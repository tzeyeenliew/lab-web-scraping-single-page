{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bfa36c8",
   "metadata": {},
   "source": [
    "### Hey Camille, I did not manage to resolve the attribute error that everyone seems to have a problem with so I combed through github looking for codes that work....Still braining parts of Jaimes Subroto's gorgeous code to see where I went wrong!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9e10a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen as uRequest\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import pandas as pd\n",
    "import requests as requests\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35871350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All good! Response code is 200\n",
      "Welcome to Nicole's Billboard Hot 100 Python Web Scraper! Thanks to Jaimes Subroto for the code!\n",
      "Would you like the data to be saved to your PC? YES/NO YES\n",
      "\n",
      "Saving this week's HOTTEST 100 songs...\n",
      "\n",
      "Web scraped data saved to your Jupyter Terminal as billboard_hot_100.csv!!!!!\n",
      "Thank you for using Nicole's Web Scraping app for Billboard HOT 100! Major thanks to Jaimes Subroto for the code!!!\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.billboard.com/charts/hot-100'\n",
    "\n",
    "try:  #thank you isi, sabina, cormac\n",
    "    request = requests.get(url)\n",
    "    request.raise_for_status()  # returns an HTTPError if the response is not OK\n",
    "    print(\"All good! Response code is\", request.status_code) \n",
    "except requests.exceptions.HTTPError as err:\n",
    "    if request.status_code == 404:\n",
    "        print(\"404: Oops, sorry we can't find that page!\")\n",
    "    else:\n",
    "        print(\"The error code is\", err.args[0]) # look up the 1st argument from HTTPError \n",
    "        \n",
    "#### AFTER THE ERROR CODE IS RETURNED PLEASE WAIT FOR THE APP TO START #####\n",
    "\n",
    "\n",
    "# Opening up connection, grabbing the page\n",
    "uClient = uRequest(url)\n",
    "page_html = uClient.read() # Offloads content into a variable\n",
    "uClient.close() # Close the client\n",
    "\n",
    "# HTML parsing\n",
    "page_soup = soup(page_html, \"html.parser\")\n",
    "\n",
    "# Grabs all information related to the top 100 songs\n",
    "containers = page_soup.select('article[class*=chart]') # *= means contains\n",
    "\n",
    "filename = 'billboard_hot_100.csv'\n",
    "f = open(filename, 'w') # w = write\n",
    "\n",
    "headers = 'Song, Artist, Last Week, Peak Position, Weeks on Chart\\n'\n",
    "\n",
    "f.write(headers)\n",
    "\n",
    "print('Welcome to Nicole\\'s Billboard Hot 100 Python Web Scraper! Thanks to Jaimes Subroto for the code!')\n",
    "\n",
    "# Asks the user if he/she wants the data to be printed to the console\n",
    "while True:\n",
    "    print_data = input('Would you like the data to be saved to your PC? YES/NO ')\n",
    "    if print_data.lower() == 'yes' or print_data.lower() == 'y':\n",
    "        print_data = True\n",
    "        print('\\nSaving this week\\'s HOTTEST 100 songs...')\n",
    "        break\n",
    "    elif print_data.lower() == 'no' or print_data.lower() == 'n':\n",
    "        print_data = False\n",
    "        print('\\nScraping this week\\'s HOTTEST 100 songs...')\n",
    "        break\n",
    "    else:\n",
    "        print('Sorry, I don\\'t understand you.... *sads*')\n",
    "\n",
    "chart_position = 1\n",
    "\n",
    "# Loops through each container\n",
    "for container in containers:\n",
    "\n",
    "    # Container storing the song name and artist name\n",
    "    song_container = container.find('div', {'class': 'chart-row__title'})\n",
    "\n",
    "    # Grabs the song name\n",
    "    song = song_container.h2.text\n",
    "    \n",
    "    # Grabs the artist name\n",
    "    try:\n",
    "        artist = song_container.a.text.strip()\n",
    "    except AttributeError:\n",
    "        artist = song_container.span.text.strip()\n",
    "\n",
    "    # Grabs the song's position last week\n",
    "    last_week_container = container.find('div', {'class': 'chart-row__last-week'})\n",
    "    last_week = last_week_container.find('span', {'class': 'chart-row__value'}).text\n",
    "\n",
    "    # Grabs the song's peak position\n",
    "    peak_position_container = container.find('div', {'class': 'chart-row__top-spot'})\n",
    "    peak_position = peak_position_container.find('span', {'class': 'chart-row__value'}).text\n",
    "\n",
    "    # Grabs the song's duration in the hot 100 (in weeks)\n",
    "    weeks_on_chart_container = container.find('div', {'class': 'chart-row__weeks-on-chart'})\n",
    "    weeks_on_chart = weeks_on_chart_container.find('span', {'class': 'chart-row__value'}).text\n",
    "\n",
    "    # Prints the chart position, song name, artist name, and related stats\n",
    "    if print_data:\n",
    "        print('\\nPosition: #{}'.format(chart_position))\n",
    "        print('Song: {}'.format(song))\n",
    "        print('Artist: {}'.format(artist))\n",
    "        print('Last Week: {}'.format(last_week))\n",
    "        print('Peak Position: {}'.format(peak_position))\n",
    "        print('Weeks on Chart: {}'.format(weeks_on_chart))\n",
    "\n",
    "    chart_position += 1\n",
    "\n",
    "    f.write('\\\"' + song + '\\\",\\\"' + artist.replace('Featuring', 'Feat.') + '\\\",' + last_week + ',' + peak_position + ',' + weeks_on_chart + '\\n')\n",
    "\n",
    "f.close()\n",
    "\n",
    "print('\\nWeb scraped data saved to your Jupyter Terminal as {}!!!!!'.format(filename))\n",
    "print('Thank you for using Nicole\\'s Web Scraping app for Billboard HOT 100! Major thanks to Jaimes Subroto for the code!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2693a989",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
